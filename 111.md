|                      |                                                                                   |      |     |                                                                      |                                      |
| -------------------- | --------------------------------------------------------------------------------- | ---- | --- | -------------------------------------------------------------------- | ------------------------------------ |
| ？                    | GR-3                                                                              | 2025 | 是   | 通过VR设备收集的人类轨迹数据可能涉及在合成VR环境中进行数据收集或视为增强数据。网络规模视觉-语言数据也可能包含合成组件。       | 旨在泛化到新对象、环境和指令。                      |
|                      | Gemini Robotics                                                                   | 2025 | 是   | **使用Gemini和FlexCap模型生成合成字幕来增强图像数据**。在MuJoCo模拟器中进行评估。                 | 旨在实现对未见环境的泛化和快速适应。                   |
| 仿真环境                 | GR00T N1                                                                          | 2025 | 是   | 利用**物理模拟器生成的合成机器人轨迹和神经视频生成模型**。使用VQ-VAE从无动作数据源中提取潜在动作作为伪标签。          | 旨在成为通用人形机器人开放基础模型，强调数据多样性。           |
| 仿真环境                 | MultiGen                                                                          | 2025 | 是   | 将大**规模生成模型集成到传统物理模拟器中，创建合成多模态数据**（例如，音频合成）。                          | 旨在解决多模态模拟和模拟到现实的迁移挑战，无需真实机器人感官或动作数据。 |
| ？                    | HybridVLA                                                                         | 2025 | 是   | 明确使用**基于扩散的连续动作预测**。微调阶段可能包括模拟数据。                                    | 统一了扩散和自回归策略，旨在提高鲁棒性和适应性。             |
| ？                    | DexTOG                                                                            | 2025 | 是   | 使用 **数据引擎通过启发式规则、扩散模型自举和基于强化学习** 的选择来生成合成训练数据（DexTOG-80K）。           | 旨在解决高自由度灵巧抓取中的任务导向性问题。               |
|                      | Interleave-VLA                                                                    | 2025 | 是   | 使用自动化管道将现有**真实世界数据集的纯文本指令转换为图文交错指令**。                                | 旨在处理图文交错指令，解决大规模图文交错具身数据集的缺乏。        |
| ai生成视觉提示             | CrayonRobo                                                                        | 2025 | 是   | 在模拟器（SAPIEN）中收集数据，结合规则启发式方法。**使用Grounded-DINO和GPT-4生成AI视觉提示**作为训练输入。 | 利用多模态提示进行机器人操作，强调对象中心化。              |
| 格式转换？                | EgoVLA                                                                            | 2025 | 是   | 主要使用自我中心人类视频预训练，**通过逆运动学和重定向将人类动作转换为机器人动作**。                         | 结合人类视频的多样性和机器人演示的精度，提高泛化能力。          |
|                      | CombatVLA                                                                         | 2025 | 是   | 在3D动作角色扮演游戏（合成环境）中，通过动作跟踪器收集视频-动作对，并格式化为思维动作序列。                      | 优化3D动作游戏中的战斗任务，实现高效决策。               |
| 扩散模型生成图像             | OG-VLA                                                                            | 2025 | 是   | 明确使用**图像扩散模型生成图像**（表示末端执行器的新位置和方向）。                                  | 结合VLA的泛化能力和3D感知策略的鲁棒性。               |
| 世界模型生成数据             | DreamGen                                                                          | 2025 | 是   | 通过**视频世界模型生成“神经轨迹**”（合成机器人数据）。使用潜在动作模型/逆动力学模型进行伪标签。                  | 旨在通过世界模型实现零样本行为和环境泛化，改变机器人学习范式。      |
| 世界模型生成数据+扩散策略        | MinD                                                                              | 2025 | 是   | 使用**视频生成模型（VGM）和扩散策略**作为“世界模型”框架的一部分。同时作为“世界模拟器”运行。                  | 旨在解决视频生成模型在机器人应用中的速度和一致性问题。          |
|                      | WorldVLA                                                                          | 2025 | 是   | 作为自回归动作世界模型，预测未来图像。                                                  | 旨在统一动作和图像理解与生成。                      |
| ？                    | AC-DiT                                                                            | 2025 | 是   | 在模拟环境中进行验证。                                                          | 旨在解决移动基座和机械臂的协调问题。                   |
| 扩散策略                 | DiffusionVLA                                                                      | 2024 | 是   | 明确**使用扩散策略进行动作生成**。使用AI生成（自生成）推理短语作为训练的一部分。                          | 整合自回归推理和扩散策略，旨在提高动作生成精度和鲁棒性。         |
| ？                    | MiniVLA                                                                           | 2024 | 是   | 在LLaVA-1.5-Instruct VQA数据集上训练，该数据集使用AI生成（机器生成）的指令遵循数据。               | 旨在减小OpenVLA的模型尺寸，同时保持或提升性能。          |
| ？                    | BAKU                                                                              | 2024 | 是   | 在模拟任务中进行评估。                                                          | 旨在高效学习多任务机器人策略，利用离线模仿学习。             |
| ？                    | CogACT                                                                            | 2024 | 是   | 使用**扩散Transformer（DiT）**进行动作预测。                                      | 旨在通过融合视觉-语言模型与动作表示来增强机器人操作功能。        |
| 通过LLM进行标注/数据创建       | LEO (An Embodied Generalist Agent in 3D World)                                    | 2024 | 是   | 数据集是“收集和生成”的，提及“使用LLM半自动收集数据”，暗示AI生成合成数据（**通过LLM进行标注/数据创建**）。        | 旨在构建能够理解和与3D世界交互的通用具身智能体。            |
| 仿真？                  | Depth Helps                                                                       | 2024 | 是   | 相关研究开发了一个可扩展的合成数据管道，**从虚拟环境中捕获实时视频深度数据**。                            | 旨在通过整合深度信息来提高预训练RGB策略的性能。            |
|                      | LLaRA                                                                             | 2024 | 是   | 使用自动化管道**从现有行为克隆数据中生成高质量的机器人指令数据**。                                  | 旨在将机器人动作策略表述为对话，并通过辅助数据改进响应。         |
| ?                    | ATM (Any-point Trajectory Modeling)                                               | 2024 | 是   | 在无动作视频数据集上预训练轨迹模型，以预测任意点的合成轨迹（未来点预测）。                                | 旨在通过预测未来轨迹来指导策略学习，实现高效的样本学习和跨具身迁移。   |
|                      | Actra                                                                             | 2024 | 是   | 在训练中采用数据增强技术，例如对动作添加高斯噪声，创建负样本。                                      | 旨在优化Transformer架构以处理机器人学习中的多模态轨迹。    |
| 数据增强                 | General Flow                                                                      | 2024 | 是   | 采用数据增强技术（如手部遮罩增强、查询点采样）来提高泛化能力。                                      | 旨在将3D流作为可扩展机器人学习的基础可供性。              |
| 扩散策略生成动作             | Helix (FigureAI)                                                                  | 2025 | 是   | 提到其使用“扩散解码器”，暗示了生成模型的使用。                                             | 旨在成为通用人形机器人控制的VLA模型。                 |
| ？                    | VLA Model-Expert Collaboration                                                    | 2025 | 是   | 提到“模型可以通过自身生成的合成数据进行微调”，但指出“生成数据中的错误操作可能降低模型性能”。这表明该方法可能使用合成数据，但需谨慎。 | 旨在通过VLA模型与专家协作实现双向操作学习。              |
| 利用GPT-4生成同义指令以增强语言泛化 | RoboFlamingo-Plus                                                                 | 2025 | 是   | **利用GPT-4生成同义指令以增强语言泛化**。                                            | 旨在通过融合深度和RGB感知来增强机器人操作。              |
| AI生成合成数据（标注）？        | InSpire                                                                           | 2025 | 是   | 通过规则启发式策略自动生成空间推理问题的地面真实答案，这是一种AI生成合成数据（标注）的方法。                      | 旨在通过内在空间推理增强VLA模型的泛化能力。              |
|                      | Hume                                                                              | 2025 | 是   | 通过“价值引导的重复采样和级联动作去噪”探索System-2慢思考范式，这些是生成模型技术。                       | 旨在在视觉-语言-动作模型中引入System-2思考。          |
| ai生成                 | Agentic Robot                                                                     | 2025 | 是   | Planner使用GPT-4o分解任务，这是一种**AI生成合成数据（规划/指令）**的方法。                      | 旨在通过脑启发框架实现可靠的长时程机器人操作。              |
| 仿真环境                 | LoHoVLA                                                                           | 2025 | 是   | 使用基于Ravens模拟器的合成数据集LoHoSet进行训练。                                      | 旨在解决长时程具身任务的统一VLA框架。                 |
| 仿真环境                 | Online RL with Simple Reward Enables Training VLA Models with Only One Trajectory | 2025 | 是   | 使用从模拟环境中直接获取的“结果级别0/1基于规则的奖励信号”。                                     | 旨在通过在线强化学习和简单奖励信号训练VLA模型。            |
|                      | BitVLA                                                                            | 2025 | 是   | LLaVA 1.5-558k数据集使用AI生成（机器生成）的指令遵循数据。                                | 旨在实现机器人操作的1位视觉-语言-动作模型。              |
| 不是                   | BridgeVLA                                                                         | 2025 | 是   | 将3D输入投影到多个2D图像，并利用2D热图进行动作预测，暗示了数据转换和生成。                             | 旨在通过输入-输出对齐实现高效3D操作学习。               |
| ？                    | Fast-in-Slow                                                                      | 2025 | 是   | 在微调阶段使用模拟数据。动作生成使用扩散目标。                                              | 旨在统一快速操作和慢速推理的双系统基础模型。               |
| ？                    | CEED-VLA                                                                          | 2025 | 是   | 通过一致性蒸馏训练学生模型，并使用Jacobi轨迹数据集（模型内部生成）。                                | 旨在通过早期退出解码提高VLA模型的推理速度。              |
