## 笔记

## TODO
今天未完成的任务:
```tasks
 ((not done) AND ((due on 2025-08-11) OR (due before 2025-08-11))) OR ((is recurring) AND (not done))
```
---
今天完成的任务:
```tasks
done
done on 2025-08-11 
```
## 新增任务

| 数据集名称     | 数据来源类别 | 是否含有对动作的语言标注 | 发布时间     | 主要模态                                                                                                       | 场景（种）                            | 跨本体数量（机器人种类）     | 技能（种）                                       | 数据规模                               | 核心特色与亮点                                                                                     | 核心任务                                      | 对应论文（APA格式引用）                                                                                                                                                                                                                      |
| --------- | ------ | ------------ | -------- | ---------------------------------------------------------------------------------------------------------- | -------------------------------- | ---------------- | ------------------------------------------- | ---------------------------------- | ------------------------------------------------------------------------------------------- | ----------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Ego-Exo4D | 真实     | 是            | 2023年12月 | 视觉数据：RGB视频（第一人称视角：Aria眼镜；第三人称视角：GoPro相机）、3D点云；其他模态：Language（专家评论、参与者叙述、原子动作描述）、Action（人类活动）、眼动追踪、IMU、多通道音频 | 123种自然场景（包括室内和室外，如厨房、运动场、音乐工作室等） | 0（无机器人，数据基于人类活动） | 8种技能领域（体育：足球、篮球、攀岩、舞蹈；音乐；程序性任务：烹饪、自行车修理、医疗） | 1286.3小时视频（221.26小时第一人称视角），5035个片段 | 首个人类技能活动多视角（第一人称与第三人称）同步视频数据集，包含3D信息、多模态数据（如眼动、音频、语言描述），支持跨视角学习、技能熟练度评估和3D姿态估计，推动VLA领域多模态理解 | 细粒度活动理解、技能熟练度评估、跨视角转换、3D手部/身体姿态估计、视频-语言学习 | Grauman, K., Westbury, A., Torresani, L., Kitani, K., Malik, J., Afouras, T., ... & Wray, M. (2024). Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives. *arXiv preprint arXiv:2311.18259*. |



