## 参考
- https://mp.weixin.qq.com/s/xJ29Uh3AHTQRA2n6IxeHYw
## 笔记
- 微调：
	- 在已有的预训练大模型上利用特定领域数据进行训练，适应特定任务和场景
- 全量微调（SFT）和高效微调
	- 全部参数与部分参数的区别
- LoRA和QLoRA
	- 1. 即低秩适配
	- 2. 将模型权重量化为低精度（如 INT4），减少内存占用
	- LoRA也可对Diffusion Model微调
	- 
- 四大应用场景
	- 对话风格微调
	- 知识灌注
	- 推理能力提升
	- Agent 能力提升
- 四个常用库（常用工具）
	- unsloth、LlamaFactory、ms-SWIFT 和 ColossalAI
	- unsloth
		- 与 HuggingFace 生态兼容，可以很容易地与 transformers、peft、trl 等库结合，以实现模型的监督微调（SFT）和直接偏好优化（DPO），仅需修改模型的加载方式，无需对现有训练代码进行修改。
		- 4bit 动态量化技术，节省时间成本
		- 显著加速微调
	- LLama-Factory，ms-SWIFT 和 ColossalAI
	- 强化学习训练，则推荐veRL和OpenRLHF等框架。
- 底层：
	- peft、LoRA、transformer 等
- ![[Pasted image 20250831140243.png]]
- 性能评估
	- EvalScope
	- ModelScope
- 多数据集按比例拼接，以保存基础能力
	- 如：
		- ![[Pasted image 20250831141207.png]]
- 数据集格式
	- ![[Pasted image 20250831141246.png]]
	- ![[Pasted image 20250831141259.png]]
	- ![[Pasted image 20250831141310.png]]
	- ![[Pasted image 20250831141320.png]]
- 