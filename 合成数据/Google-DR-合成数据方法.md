# VLA模型合成数据方法研究报告

## 1. 引言

### 1.1. VLA模型概述及其数据需求

视觉-语言-动作（VLA）模型代表了人工智能领域的一个重要发展方向，它们是旨在整合视觉感知、自然语言理解和行动规划能力的新兴多模态系统 1。这些模型赋予智能体解释环境、理解人类指令并自主执行具身任务的能力 1。VLA模型的核心在于将视觉观测（如图像或视频帧）和文本指令编码到共享的嵌入空间中，并从这一共享表示中生成结构化的动作序列，有效弥合了感知、语言理解和行动规划之间的鸿沟 1。

VLA模型的架构通常包含感知、推理和控制等多个阶段。其动作输出是高维度的控制信号，例如七维的位姿控制（x, y, z, roll, pitch, yaw），且动作序列的长度（即动作时间步长，action horizon）可变，例如π0模型的动作时间步长可达50个动作 1。VLA模型的发展标志着基础模型演进的最新阶段，从大型语言模型（LLMs）到视觉-语言模型（VLMs），最终扩展至视觉-语言-动作模型 2。它们在机器人指令遵循、多模态感知与指令接地、高层规划以及少样本提示学习等方面展现出巨大潜力，是实现通用具身智能的关键路径 2。VLA模型能够统一感知、自然语言理解和具身动作，有望成为通用的机器人策略 4。

VLA模型对数据质量和多样性的内在需求是其复杂性和通用性目标的直接体现。VLA模型的高级功能，例如指令遵循和高层规划，直接依赖于其对环境的精确感知和对指令的深刻理解。这些能力的习得，反过来要求训练数据能够提供丰富的视觉-语言-动作关联，从而确保模型能够有效地将指令“接地”并生成正确的物理动作。因此，VLA模型需要大规模、高质量、多模态的数据集，这些数据集必须包含丰富的视觉观测、精确的自然语言指令、详细的机器人本体感受状态以及与之对应的准确动作序列 1。数据的多样性对于模型泛化至关重要，需要覆盖各种环境、物体、任务和交互模式 3。如果数据缺乏多样性，模型将容易过拟合于特定场景；如果数据质量不高或标注不精确，模型将难以学习到正确的感知-动作映射。这种多模态、多阶段的特性决定了模型需要处理异构且复杂的输入，而其旨在实现“通用机器人策略”和“具身智能”的目标，则意味着它们必须能够在各种未见过的真实世界场景中执行多样化的任务。为了实现这些目标，模型不能仅仅记忆训练数据，而必须学习到可泛化的、鲁棒的特征表示和决策策略。高质量、多样化的多模态数据是VLA模型实现其通用性和鲁棒性的根本基石。

### 1.2. 合成数据在VLA模型训练中的重要性

收集大规模、多样化且标注精确的真实世界机器人数据是极其昂贵、耗时且难以扩展的。这包括获取不同光照条件、遮挡情况、物体变体以及各种任务执行过程中的视觉、语言和动作数据 5。真实世界数据往往难以覆盖所有边缘案例和罕见故障，这限制了模型在复杂和不可预测环境中的鲁棒性 8。

合成数据是弥合“数据鸿沟”和实现“通用具身智能”的战略性解决方案，而非仅仅是数据补充。真实世界数据收集的根本性限制——高成本、耗时、难以规模化，以及无法全面覆盖所有可能的场景和边缘案例——构成了VLA模型发展中的一个核心“数据鸿沟” 5。合成数据通过模拟或生成式AI技术，能够以低成本、高效率的方式大规模生产数据，显著节省训练时间和资源 5。在模拟环境中，可以精确控制环境参数（如光照、纹理、物体位置、场景杂乱度）和物理属性，从而系统性地生成多样化的数据，包括真实世界中难以捕捉的极端场景和边缘案例 6。合成数据可以自动生成精确的标注信息，如物体位置、姿态、语义分割、动作序列等，避免了人工标注的误差和耗时 9。关于DreamGen的研究表明，通过视频世界模型和生成式AI生成“神经轨迹”，机器人学习的范式正在从“扩展人类示教数据”转向“通过世界模型扩展GPU计算和数据生成” 12。这表明合成数据不再是真实数据的辅助，而是可以成为训练VLA模型以实现强大泛化能力的核心数据源。这种范式转变的深层影响在于，它使得VLA模型能够学习到更鲁棒、更具泛化性的特征表示，因为它们在训练阶段接触到了比任何真实数据集都更广阔、更受控的场景分布。通过主动控制数据生成过程，研究人员可以更有效地解决过拟合问题，并提高模型在真实世界中面对未知情况时的适应性。因此，合成数据是加速VLA模型从实验室走向实际应用、实现真正通用具身智能的战略性推动力。

### 1.3. 报告结构

本报告将首先概述VLA模型及其对数据的独特需求。随后，将深入探讨VLA模型合成数据的主要方法，包括基于模拟器的环境与交互生成、基于大型语言模型（LLM）的指令与规划生成，以及基于扩散模型的视觉与动作合成。接着，报告将分析数据增强和域随机化策略在提升VLA模型泛化能力中的作用。最后，报告将讨论当前面临的挑战，如现实差距和数据一致性问题，并展望VLA模型合成数据领域的未来研究方向。

## 2. 合成数据生成方法

### 2.1. 基于模拟器的环境与交互生成

#### 程序化生成与3D资产合成

程序化生成是一种利用算法为数字内容（包括景观、角色、纹理和变体）注入生命的技术 11。它通过一系列预定义的规则、参数或“种子”作为基础，算法遵循这些规则生成复杂的模式、结构和环境。通过引入随机变化，确保每次迭代的结果都是独特且有机的 11。例如，Autodesk 3ds Max和Maya中的Bifrost工具能够创建程序化生成的图像和3D内容。在游戏领域，如《Rogue》、《Minecraft》和《无人深空》（No Man's Sky）等游戏，通过随机生成关卡和看似无限的世界，展示了程序化生成的强大能力 11。

程序化生成为VLA模型提供了无限且多样化的训练场景，是实现开放世界泛化的基础。传统的数据收集和手动3D资产创建成本高昂且多样性有限，难以覆盖VLA模型在开放世界中可能遇到的所有场景。程序化生成通过算法和规则能够创建动态、不断演变的世界和无限变体，从而解决了传统数据收集的规模和多样性瓶颈 11。对于VLA模型而言，这意味着可以系统性地生成具有不同布局、物体属性、纹理和环境条件的海量视觉场景。这种能力至关重要，因为它能够迫使模型学习到对环境变化不敏感的鲁棒特征，从而提高其在未见过的、复杂真实世界环境中的泛化能力。它为VLA模型提供了探索广阔状态空间的机会，使其能够适应各种未知情况，是实现真正开放世界具身智能的根本性技术。

#### 数字孪生与物理仿真

数字孪生是真实世界环境的物理精确虚拟副本，具备准确的物理属性 9。在这些数字孪生中，用户可以运行多种场景，并随机化照明、颜色、纹理和位置等参数，从而生成高质量的合成数据 9。世界基础模型（WFMs）是理解空间动力学和物理的神经网络，能够进一步增强模拟生成的合成数据，以实现照片级真实感。WFMs通过将模型输出“接地”于结构化、可验证的信息，有效防止了幻觉的产生 9。

数字孪生和物理仿真为VLA模型提供了高保真、可控的具身交互数据，是学习复杂物理动态和精细操作的关键。VLA模型不仅需要理解视觉和语言，更需要将这些理解转化为物理世界中的精确动作。VLA模型生成“结构化动作序列”的能力，意味着对物理规律的准确把握至关重要 1。数字孪生是“物理精确的虚拟副本”，而WFMs能够“模拟真实世界条件，理解空间动力学和物理” 9。这超越了单纯的视觉生成，确保了合成数据在物理行为上与真实世界高度一致。这种高保真度的数据生成能力使得VLA模型能够学习精细操作，例如在模拟中反复训练抓取、推拉等动作，模型可以学习到在不同物理条件下（如摩擦力、重力）的精确控制。同时，模型可以通过观察模拟中的物理交互，学习物体之间的因果关系和动态变化，从而更好地预测动作结果，并降低在真实机器人上进行危险或耗时实验的风险。物理精确的合成数据直接导致VLA模型在学习具身任务时能够形成更准确的“世界模型”，从而在真实世界中表现出更高的动作成功率和鲁棒性。

#### 案例分析

##### PhysicsGen (MIT)

PhysicsGen是一个模拟驱动的系统，旨在为灵巧机器人定制训练数据 14。它通过三步过程实现：首先，使用VR头显跟踪人类手部操作物体（如积木），同时在3D物理模拟器中映射这些交互；其次，将人类演示的映射点重新映射到特定机器人模型的关节配置；最后，利用轨迹优化来模拟完成任务的最有效运动 14。该系统能够将几十个VR演示转化为近3000个模拟，生成高质量的指令并映射到机器人精确的机械配置。这使得机器人能够以多种方式处理任务，并在一种方法失败时尝试其他运动 14。

PhysicsGen展现了从少量人类直观演示高效生成大规模、机器人特定且可泛化训练数据的潜力，是“示教-模拟-优化”循环的典范。VR头显跟踪的“几十个VR演示”可以转化为“近3000个模拟”，这直接解决了真实世界示教数据收集的效率和规模问题 14。PhysicsGen能够“定制机器人训练数据以适应特定机器”，并“映射到机械臂和手等机械伙伴的精确配置” 14。这意味着它不仅生成通用数据，还能根据特定机器人硬件的运动学和动力学特性进行定制，从而提高数据在特定机器人上的有效性。这种方法的核心在于将人类的直观操作（VR演示）作为“种子”，通过物理模拟器进行大规模复制和变异，并通过“轨迹优化”确保生成动作的效率和可行性。这形成了一个高效的数据生成循环，极大地加速了VLA模型的训练和部署，特别是在需要精细操作的场景中。从少量人类演示到大规模、机器人特定合成数据的转化能力，直接降低了训练VLA模型的成本和门槛，加速了机器人技能的习得和泛化。

##### AutoBio

AutoBio是一个模拟框架和基准，专门用于评估生物实验室环境中的机器人自动化，特别是VLA模型 15。它通过以下方式扩展了现有模拟能力：数字化真实世界实验室仪器、开发专门的物理插件（如螺纹机制、制动机制、偏心机制、准静态液体模拟）以及支持动态界面和透明材料的渲染堆栈（基于物理渲染PBR） 15。AutoBio提供了场景初始化、随机化和专家演示合成（使用IK解算器和TOPP）的基础设施，支持对VLA模型在语言接地、视觉理解和高精度操作方面的标准化评估。基线评估显示，VLA模型在精度操作、视觉推理和指令遵循方面仍存在显著差距 15。

AutoBio揭示了为特定复杂专业领域（如生物实验室）生成高精度、多模态VLA数据的必要性和方法，并强调了领域特定物理建模的重要性。生物实验室环境的“结构化协议、高精度、多模态交互、透明液体和容器”等独特挑战，是通用模拟器难以有效处理的 15。AutoBio通过“仪器数字化”、“专门的物理插件”（如螺纹、制动、准静态液体）和“PBR渲染”等技术，解决了这些领域特定的复杂物理现象和视觉挑战。这表明，对于VLA模型在特定专业领域（如医疗、工业、农业）的部署，通用合成数据方法可能不足，需要高度专业化和定制化的模拟器来确保数据的物理准确性和视觉真实感。这种定制化的合成数据生成方法，能够为VLA模型提供在特定高精度任务中所需的精确感知和操作数据，从而提高其在该领域的性能和可靠性。基线评估中发现的“显著差距”也反过来证明了这些领域特定挑战的复杂性，以及需要更精细、更准确的合成数据来弥合这些差距。领域特定的物理建模和渲染能力直接导致合成数据能够更真实地反映复杂专业场景的特性，从而有效训练VLA模型处理这些场景中的高精度操作和视觉推理，推动VLA模型在更广泛的实际应用中落地。

##### EmbodiedGen

EmbodiedGen是一个用于交互式3D世界生成的平台，它利用生成式AI实现高质量、可控、逼真的3D资产的低成本可扩展生成，这些资产具有准确的物理属性和真实世界尺度，并以URDF格式提供，可直接导入模拟器 18。其核心模块包括Image-to-3D、Text-to-3D、Texture Generation、Articulated Object Generation、Scene Generation和Layout Generation 18。EmbodiedGen通过生成多样化和交互式的3D世界，解决了具身智能研究中泛化和评估的数据挑战。它支持从图像或文本提示生成多样化的对象和背景资产，并支持纹理编辑以增强视觉丰富性 18。

EmbodiedGen通过模块化和生成式AI实现了3D世界和资产的自动化、多样化构建，为VLA模型提供了前所未有的丰富和可控的训练环境，加速了具身智能的研发。传统3D资产的手动创建和标注成本高、真实感有限，严重阻碍了数据驱动方法的扩展性 18。EmbodiedGen通过“Image-to-3D”、“Text-to-3D”、“Texture Generation”等模块，实现了从不同输入（图像、文本）自动生成“物理精确、照片级真实感”的3D资产和场景布局 19。这种能力使得VLA模型可以快速获得具有无限变体（例如，不同物体组合、纹理、光照、场景布局）的训练数据，这对于提高模型的泛化能力至关重要。研究人员可以精确控制生成数据的属性，以针对性地训练模型对特定环境因素的鲁棒性。自动化生成大大降低了获取高质量3D数据的成本和时间，使得研究团队能够将更多精力投入到模型开发和算法优化上。同时，支持“real-to-sim digital twin creation”意味着可以根据真实世界的物体快速生成其数字副本，进一步缩小模拟与现实之间的差距 19。EmbodiedGen的出现，使得VLA模型能够在一个前所未有的丰富和可控的虚拟环境中进行训练，从而加速了具身智能在复杂、开放世界场景中的发展和部署。

##### Synthetica

Synthetica是一种用于大规模合成数据生成的方法，主要目标是训练鲁棒的视觉对象检测器，作为机器人应用中状态估计的前端 5。它通过大规模合成数据生成来提高从模拟到真实世界的迁移能力，并实现快速实时推理 5。Synthetica解决了过度依赖真实世界数据进行机器人感知训练的问题，因为真实数据收集和标注耗时且昂贵 5。它在YCBV对象检测基准上取得了最先进的性能 5。

Synthetica凸显了合成数据在提升机器人底层感知能力（如目标检测）方面的关键作用，为VLA模型提供了更稳健的视觉输入基础。VLA模型首先需要准确地感知环境中的物体，其性能高度依赖于视觉感知模块的鲁棒性 1。真实世界感知数据在不同光照、遮挡和视觉伪影下的收集和标注是“极其耗时且昂贵的” 5。Synthetica通过“大规模合成数据生成”来训练“鲁棒的状态估计器”和“目标检测器” 5。这意味着它能够生成大量具有多样化视觉条件（如不同光照、部分遮挡、背景变化）的图像，从而训练出在各种复杂视觉条件下都能可靠运行的感知模型。稳健的视觉感知能力是VLA模型成功执行任务的前提。Synthetica通过合成数据直接提升了这一底层能力，从而间接提高了VLA模型整体的准确性、鲁棒性和在真实世界中的可靠性。如果感知环节出现错误，后续的语言理解和动作规划都将受到影响，因此，合成感知数据是构建高性能VLA模型的关键一环。

### 2.2. 基于大型语言模型 (LLM) 的指令与规划生成

#### 自然语言指令与任务分解

大型语言模型（LLMs）在理解和生成自然语言方面展现出卓越能力，这使得它们能够将人类的高层自然语言指令转化为机器人可执行的规划目标和多阶段子任务的详细计划 23。LLMs能够将复杂的长时序任务分解为更小、更易于管理的顺序子任务，例如“取出鞋子”的任务可以分解为“打开盒子”、“抓取第一只鞋”、“放置第一只鞋”等步骤 24。LLMs有助于将语言指令与环境感知相结合，实现指令的“接地”，确保机器人理解指令在特定场景中的含义 2。LLM生成的结构化任务计划和子任务描述可以直接用于指导合成数据的生成过程，确保生成的视觉-语言-动作数据与高层人类意图保持一致，从而提高VLA模型学习复杂任务的效率和准确性。

LLMs是VLA模型实现高层语义理解和复杂任务规划的关键，通过生成结构化指令和任务分解，弥合了人类意图与机器人动作之间的语义鸿沟。人类指令通常是高层、抽象的自然语言（例如“收拾房间”），而机器人需要低层、精确的动作序列，这是VLA模型面临的一个核心“语义鸿沟”。LLMs能够将这种高层指令转化为“详细的任务计划”和“多阶段子任务” 24。这种能力使得LLMs能够充当VLA模型的高层“大脑”，将模糊的人类意图转化为清晰、可执行的机器人规划。LLM生成的任务分解和详细计划可以直接作为合成数据生成器的输入。例如，一个模拟器可以根据LLM生成的“打开盒子”指令，自动生成该子任务的视觉场景和机器人动作序列。这不仅自动化了数据生成，也确保了生成数据的语义一致性和任务完整性。LLMs在指令生成和任务分解方面的能力，直接提升了合成数据在语义层面的丰富度和结构化程度。这使得VLA模型能够学习到更高级别的推理和规划能力，从而更好地理解和执行复杂、长时序的具身任务。

#### 逻辑形式与行为序列合成

神经语义解析器能够将自然语言语句映射到可执行的逻辑形式（如功能查询语言FunQL），这些逻辑形式可以针对特定任务环境（如知识库或数据库）执行以产生响应 26。解析器通过基于转换的方法生成树状结构的逻辑形式，结合通用树生成算法和逻辑语言定义的领域通用语法。它利用循环神经网络（RNNs）和注意力机制来处理自然语言与逻辑形式标记之间的不匹配，确保生成逻辑形式的正确性和语义有效性 26。神经语义解析器可以在完全监督、弱监督或远距离监督的设置下进行训练，以适应不同程度的标注数据可用性 26。将自然语言指令转化为精确的逻辑形式，为VLA模型提供了从高层语义到低层可执行行为的结构化桥梁。这确保了合成指令的精确性和可验证性，对于需要严格遵循指令的机器人任务至关重要。

语义解析器为VLA模型提供了从自然语言到可执行代码或逻辑的结构化桥梁，确保指令的精确性和可验证性，是生成高质量、无歧义合成指令数据的关键。自然语言固有的模糊性和多样性是机器人理解指令的障碍。例如，“拿起苹果”可能在不同场景下对应不同的物理动作。神经语义解析器能够将自然语言转化为“可执行的逻辑形式” 26。这种转化过程确保了指令的“精确性”和“可验证性”，因为它将模糊的语言映射为机器可以无歧义地解释和执行的结构化表示。在合成数据生成过程中，语义解析器可以用于生成精确指令，确保生成的自然语言指令能够被准确地转化为机器人可执行的逻辑形式，从而避免训练数据中的歧义。同时，它还可以验证生成的合成视觉-语言-动作数据中，语言指令与动作序列是否在逻辑上一致。通过这种结构化的转化，可以生成更“干净”、更“一致”的训练数据，减少模型因指令理解偏差而产生的错误。语义解析器提供的精确逻辑形式，直接提升了合成指令数据的质量和可用性，使得VLA模型能够学习到更可靠的语言接地和动作规划能力，从而在执行复杂任务时表现出更高的成功率。

#### 奖励函数与高层规划

LLMs可以用于学习奖励函数，将自然语言命令表示为目标状态奖励函数，以指导强化学习（RL）过程 27。例如，通过提供自然语言命令和对应的初始/终止MDP状态对，可以诱导组合范畴语法（CCG）语义解析器来学习这种映射 27。LLM驱动的高层规划对于分解复杂任务至关重要，能够将长时序任务分解为可管理的子任务，并生成相应的执行代码或计划 2。例如，RoboHorizon利用LLMs生成多阶段子任务的密集奖励结构，以帮助机器人更好地识别和执行长时序任务 24。LLMs在奖励函数设计和高层规划中的应用，使得合成数据能够更有效地引导VLA模型学习复杂、目标导向的行为。这对于解决强化学习中稀疏奖励问题和长时序任务规划挑战具有重要意义。

LLMs在奖励函数设计和高层规划中的应用，使得合成数据能够更有效地引导VLA模型学习复杂、目标导向的行为，并克服传统强化学习的稀疏奖励挑战。传统的强化学习（RL）在处理复杂、长时序任务时，常面临“稀疏奖励”问题，即机器人只有在完成任务时才能获得奖励，导致学习效率低下。LLMs能够从自然语言指令中生成“密集奖励结构”和“目标状态奖励函数” 24。这为机器人提供了在任务执行过程中更频繁、更具体的反馈信号，极大地加速了RL的训练过程。LLMs在“任务分解”和“高层规划”中的作用，使得LLM能够将一个复杂任务分解为一系列子任务 2。合成数据生成器可以为每个子任务生成对应的视觉-语言-动作数据，并为这些子任务定义中间奖励。LLMs通过生成结构化的任务计划和密集的奖励信号，使得合成数据能够更精确地模拟人类的意图和任务的逻辑结构。这不仅提高了数据生成的效率，也确保了生成数据与复杂任务的逻辑结构保持一致，从而使VLA模型能够学习并执行更复杂的、长时序的行为。LLMs在奖励函数和高层规划方面的能力，直接提升了合成数据对VLA模型学习复杂行为的指导效力。这使得模型能够更有效地探索和优化其策略，从而在实际应用中展现出更强的任务完成能力。

### 2.3. 基于扩散模型的视觉与动作合成

#### 轨迹生成与预测

扩散模型是一类强大的生成模型，能够表示高维数据分布，并在自主驾驶的轨迹预测和生成中表现出色 28。扩散模型能够对多模态分布进行建模，并对高维输入和输出空间具有鲁棒性。这使其在机器人操作中能够生成多种可能的有效解决方案（冗余解），从而提高泛化能力和机器人的多功能性 29。扩散模型的一个显著特点是其能够通过基于梯度的引导采样，在推理阶段根据用户偏好或额外要求来调整生成的轨迹分布，而无需额外的模型训练成本 28。扩散模型可以用于生成高保真、多样化的机器人动作轨迹，包括复杂的运动序列和抓取姿态，这对于VLA模型学习精细和多样的操作技能至关重要。

扩散模型通过生成多模态、高维轨迹数据，极大地丰富了VLA模型的动作空间和泛化能力，尤其是在处理具身任务中的冗余解和不确定性方面。机器人执行任务时，通常存在多种可行的动作序列（冗余解），例如抓取一个物体可以有不同的角度和方式。传统的模仿学习可能难以捕捉这种多样性。扩散模型在“高维数据分布”和“多模态分布”建模上的强大能力，意味着它不仅能生成单一的“正确”轨迹，还能生成一系列“同样有效”的、符合物理规律的动作轨迹 28。通过生成更多样的轨迹数据，VLA模型可以学习到在不同条件下（例如，物体位置略有变化、环境约束不同）执行任务的多种方式。这种多样性训练提高了模型的鲁棒性和适应性，使其在真实世界中遇到轻微变体时仍能成功执行任务。此外，“基于梯度的引导采样”能力意味着可以在生成轨迹时注入特定的偏好或约束，从而生成符合特定需求的合成数据，进一步优化训练过程 28。扩散模型生成的多样化、高维轨迹数据，直接扩展了VLA模型对动作空间的理解和探索，使其能够学习到更灵活、更具适应性的策略，从而在复杂和不确定的真实世界环境中表现出更强的泛化能力。

#### 世界模型与未来状态预测

世界模型对于具身AI智能体理解和预测环境至关重要，使它们能够对未来情景进行想象，从而更好地推理、决策、适应和行动 30。3D-VLA模型通过引入生成式世界模型，无缝连接3D感知、推理和动作。它建立在一个3D-based LLM之上，并训练一系列具身扩散模型来预测目标图像和点云，以弥补现有VLA模型缺乏3D物理世界整合的问题 30。LaDi-WM模型通过预测未来状态的潜在空间（利用预训练的视觉基础模型中的几何和语义特征），实现预测性操作。它设计了一种扩散策略，通过结合预测状态来迭代优化输出动作，从而生成更一致和准确的结果 35。结合世界模型和扩散模型能够实现对未来环境和动作的预测性合成，从而为VLA模型提供前瞻性训练数据，使其能够进行基于模型的规划和学习。

结合世界模型和扩散模型能够实现对未来环境和动作的预测性合成，从而为VLA模型提供前瞻性训练数据，使其能够进行基于模型的规划和学习。VLA模型需要进行“动作规划”和“长时序规划” 1。成功的规划需要模型具备预测未来状态的能力。世界模型对于具身AI智能体理解和预测环境至关重要，并使其能够推理、决策、适应和行动 31。世界模型赋予了VLA模型“想象未来场景”的能力。扩散模型能够将世界模型的抽象预测具象化为“目标图像和点云”或“未来状态的潜在空间” 30。这意味着模型不仅能“想”，还能“看”到未来的可能状态。这种结合使得合成数据生成器能够创建包含复杂环境动态和机器人-物体交互的未来状态序列。例如，可以生成机器人执行某动作后，物体如何移动、环境如何变化的视频或3D点云。这为VLA模型提供了丰富的、与长期规划相关的状态-动作-未来状态数据。预测性合成数据直接支持了VLA模型进行“基于模型的规划”，使其能够在训练中接触到更复杂的决策路径和潜在的未来结果。这提高了模型的规划能力和对环境动态的理解，从而在真实世界中能够更智能、更有效地执行长时序任务。

#### 神经轨迹与行为泛化

DreamGen是一个四阶段管道，通过视频世界模型生成“神经轨迹”（合成机器人数据） 12。它旨在实现零样本行为泛化和零样本环境泛化 12。DreamGen首先在目标机器人上微调视频世界模型（图像到视频扩散模型），以学习机器人动力学。然后，通过初始帧和语言指令提示这些模型，生成包含域内行为以及新颖行为和新颖环境的机器人视频。最后，通过潜在动作模型或逆动力学模型（IDM）提取伪机器人动作，并将这些带有伪动作标签的视频（即神经轨迹）用于下游的视觉运动策略学习 12。DreamGen使得人形机器人能够在仅需单个抓取放置任务的示教数据的情况下，在新的环境中执行22种新行为。数据扩展分析显示，增加神经轨迹的数量与下游机器人策略性能之间存在对数线性关系，为扩展机器人训练数据开辟了新途径 12。神经轨迹的生成范式转变了机器人学习的数据扩展方式，从依赖大量人工示教数据转向通过世界模型和生成式AI来扩展GPU计算和数据生成，极大地提升了泛化能力。

神经轨迹的生成范式转变了机器人学习的数据扩展方式，从依赖大量人工示教数据转向通过生成式AI进行计算扩展，极大地提升了VLA模型的泛化能力和数据效率。传统的机器人学习高度依赖人类示教数据，而这些数据收集成本高昂，且难以覆盖所有可能的行为和环境变体，从而限制了模型的泛化能力 37。DreamGen详细描述了如何利用“视频世界模型”和“图像到视频扩散模型”生成“神经轨迹” 12。这不仅仅是数据增强，而是一种根本性的转变——从“扩展人类示教数据”到“通过世界模型扩展GPU计算” 12。DreamGen能够实现“零样本行为泛化和零样本环境泛化”，这意味着VLA模型可以在未见过的新行为和新环境中执行任务，而无需额外的真实世界示教 12。这是通过生成包含这些新颖场景的合成神经轨迹来实现的。此外，增加神经轨迹的数量与下游机器人策略性能之间存在对数线性关系，表明通过合成数据可以高效地提升模型性能，减少对昂贵真实数据的依赖 12。这种生成式AI驱动的数据扩展能力，直接打破了真实数据收集的瓶颈，使得VLA模型能够在一个更广阔、更受控的虚拟数据空间中进行训练。这不仅加速了模型开发，更重要的是，它使得VLA模型能够学习到更强大、更具适应性的泛化能力，从而在真实世界的复杂和动态环境中表现出色。

## 3. 数据增强与域随机化策略

### 3.1. 增强数据多样性与鲁棒性

数据增强和域随机化是提高机器人识别和与训练中未见物体交互能力的关键技术 7。它们旨在通过引入多样性来提升VLA模型在真实世界中的鲁棒性和泛化能力。域随机化方法通过随机化模拟环境中的视觉和物理参数（例如，光照、纹理、物体位置、背景、物理属性等），迫使智能体学习对这些无关细节不变的特征 7。这有助于模型避免过拟合于特定的模拟环境，从而实现更好的真实世界泛化 7。数据增强方法则通过对现有数据进行变换（如旋转、缩放、裁剪、颜色抖动等）来增加训练数据的多样性，使模型接触到更广泛的物体外观和方向，从而促进鲁棒性和对新物体的泛化 7。这些策略对于弥合模拟与现实之间的“现实差距”（sim-to-real gap）至关重要。通过在合成数据中引入足够的变异性，VLA模型能够学习到更具普适性的表示，从而在真实世界中表现出更强的适应性和可靠性 6。

数据增强和域随机化是弥合“现实差距”和提升VLA模型泛化能力的核心手段，其本质是通过受控的“噪声”和“变化”来模拟真实世界的复杂性。“现实差距”是指模型在合成数据上表现良好，但在真实世界数据上失败的问题 38。这不仅仅是数据量的问题，更是数据分布和复杂性匹配的问题。域随机化通过“随机化视觉和物理参数”来“迫使智能体学习对这些无关细节不变的特征” 7。这表明域随机化不是简单地增加数据，而是有策略地引入“变化”，模拟真实世界中不可避免的变异性（如光照、纹理、物体摆放等）。这种“受控的噪声”使得模型学习到的特征更具鲁棒性，不会过拟合于模拟环境的特定细节。它强迫模型关注任务相关的核心特征，而不是表面上的视觉或物理属性。通过系统性地引入多样性和变化，域随机化主动缩小了模拟与现实之间的差距，从而直接提升了VLA模型在真实世界中对未见场景、物体和条件的泛化能力。这使得合成数据训练的模型能够更可靠地部署到实际应用中。

### 3.2. 域随机化关键参数与应用

RoboTwin 2.0是一个可扩展的模拟框架，用于双臂机器人操作，它在五个关键轴向上整合了结构化域随机化，以增强数据多样性和策略鲁棒性 6。

- **杂乱度 (Clutter):** 通过在工作空间中随机填充与任务无关的干扰物体来创建杂乱场景。利用RoboTwin-OD对象资产库（包含731个带标注对象），合成多样且语义丰富的杂乱场景。通过预计算碰撞体积和应用碰撞感知放置，确保物理合理性 6。这使得VLA模型在复杂、拥挤的真实环境中能够更准确地识别和操作目标物体，提高对环境变化的鲁棒性。
    
- **背景纹理 (Background Textures):** 使用程序化方法和生成模型（如Stable Diffusion v2）生成的纹理库，随机化桌面表面和周围背景。通过LLM结合网络爬虫收集多样化的文本提示，并进行人工验证，生成了12,000张高质量纹理 6。这使得VLA模型暴露于广泛的视觉分布，有助于缓解对干净、合成环境的过拟合，增强模型在不同视觉背景下的适应性。
    
- **照明变化 (Lighting Variation):** 在模拟管道中应用照明随机化，包括随机化光源的颜色、类型、强度和位置，以模拟真实世界中光照条件的多样性 6。这提高了VLA模型在不同光照条件（如阴影、高光、不同色温）下的鲁棒性，使其在真实世界照明变化下也能保持稳定性能。
    
- **桌面高度 (Tabletop Heights):** 在数据生成过程中，从物理合理范围内均匀采样桌面高度，引入视点和机器人与被操作物体之间空间关系的变化 6。这提高了VLA模型对不同操作平台高度的鲁棒性，使其能够适应真实世界中多变的物理部署环境。
    
- **轨迹级多样化语言指令 (Trajectory-Level Diverse Language Instructions):** 使用多模态大型语言模型（MLLMs）自动生成多样化的任务指令和物体描述，包括任务指令模板和反映几何、外观、部件属性的物体描述 6。这在轨迹层面引入语言多样性，显著提高VLA模型对未见指令和场景配置的泛化能力，使其能够理解和响应更广泛的人类自然语言指令。
    

此外，RoboTwin 2.0还引入了**具身感知抓取适应 (Embodiment-aware Grasp Adaptation)** 机制。针对不同机器人手臂的自由度（DoF）和运动学结构差异，为每个物体标注了多样化的操作候选（包括多个抓取轴和接近方向），确保数据集捕捉操作多样性和机器人特定偏好 6。这使得VLA模型能够学习到更适合特定机器人硬件的操作策略，进一步提高真实世界部署的成功率。

精细化的多维度域随机化是构建可泛化VLA模型的必要条件，它通过系统性地模拟真实世界的复杂性和变异性，主动缩小了“现实差距”。“现实差距”并非单一问题，而是由多种因素（如光照、纹理、物体放置、环境动态）共同造成的 38。RoboTwin 2.0在“杂乱度、照明、背景、桌面高度、语言指令”等五个维度上的结构化域随机化，表明仅仅随机化一两个参数是不足够的；为了有效弥合现实差距，域随机化必须是多维度、结构化且精细化的 6。每个参数的随机化都针对真实世界中VLA模型可能遇到的特定变异源。这种系统性的方法不是被动地等待真实数据来暴露问题，而是通过在合成数据生成阶段主动引入这些变异性，从而迫使VLA模型学习到更鲁棒、更具泛化性的特征。例如，语言指令的随机化确保模型不过度依赖特定措辞，而杂乱度随机化则提高了模型在复杂视觉环境中的目标识别和操作能力。这种精细化的多维度域随机化策略，直接导致了VLA模型在真实世界中对“未见场景”和“未见指令”的显著泛化能力提升 6。它证明了通过智能的合成数据生成，可以有效克服真实世界数据的限制，从而加速VLA模型在复杂实际应用中的部署。

### 3.3. 案例分析：RoboTwin 2.0

RoboTwin 2.0作为一个可扩展的模拟框架，通过自动化、大规模生成多样化和逼真的数据，显著增强了真实世界中的双臂机器人操作能力 6。该框架预收集了超过100,000条域随机化的专家轨迹，这些数据涵盖了50个双臂任务和五种机器人具身形态。实验结果表明，其在代码生成成功率方面提高了10.9%，并显著提高了对新颖真实世界场景的泛化能力 6。经过RoboTwin 2.0数据集微调的VLA模型，在未见场景的真实世界任务上实现了367%的相对改进（从9.0%提高到42.0%）。仅用其合成数据训练的零样本模型也达到了228%的相对增益，这突出显示了其在没有真实世界监督情况下的强大泛化能力 6。RoboTwin 2.0的数据生成管道利用多模态大型语言模型（MLLMs）和仿真循环反馈，迭代验证和改进任务执行代码，进一步提高了数据质量和多样性 6。

RoboTwin 2.0的成功证明了大规模、结构化合成数据在推动VLA模型真实世界泛化方面的巨大潜力，并确立了合成数据作为训练VLA模型核心数据源的地位。RoboTwin 2.0提供了明确的量化数据（“超过100,000条专家轨迹”、“367%的相对改进”、“零样本模型228%的相对增益”），这些数字是合成数据有效性的强有力证据 6。这不仅仅是理论上的可行性，而是实践中可衡量的显著效果。RoboTwin 2.0的成功表明，通过智能的合成数据生成策略，可以有效地克服真实世界数据收集的限制，从而加速VLA模型在复杂实际应用中的部署。这种方法将合成数据从一个辅助角色提升为训练VLA模型的核心数据源，因为它能够提供真实数据难以企及的规模、多样性和精确控制。这种转变对于推动具身智能的发展至关重要，因为它使得研究人员能够更高效地探索和优化VLA模型，使其在面对真实世界中各种复杂和不可预测的情况时，依然能够保持鲁棒性和高成功率。

## 4. 挑战与未来展望

### 4.1. 现实差距与数据一致性挑战

“现实差距”是指模型在合成数据上训练良好，但在真实世界数据上部署时性能下降的技术问题 38。这一问题并非新近出现，而是自20世纪中叶模拟技术诞生以来就一直存在的挑战，并贯穿于统计、离散事件和视觉交互等不同模拟范式中 38。合成数据本身并不能完全弥合这一差距，因为模拟的设置和参数仍然需要真实世界数据的支撑 38。

当前，VLA模型的合成数据在一致性方面也面临多重挑战。这包括：

- **偏置的时间分布：** 现有基准测试在捕捉视觉-语言关联时，可能存在偏置的时间分布，导致模型在处理随时间演变的真实世界情况时表现不佳 40。
    
- **不精确的标注：** 即使在合成数据中，也可能存在不精确的标注，例如人类标注者对时间事件的感知不一致，导致标注不可靠 40。
    
- **不足的组合性：** 数据集可能缺乏足够的组合性，限制了模型对复杂场景和指令的泛化能力 40。
    
- **不一致的演示和动作：** 在微调VLA模型时，人类收集的演示数据可能存在次优或不一致的动作轨迹，尤其是在需要精确控制的接触密集型环境中 41。这会导致模型性能不稳定，难以泛化到未见状态 41。
    

这些数据一致性问题直接影响VLA模型的泛化能力和可靠性。如果训练数据在语义、时间或物理行为上存在内部矛盾，模型将难以学习到鲁棒且可信赖的策略，从而在真实世界部署时面临性能下降和不可预测行为的风险 43。

### 4.2. 克服挑战的策略

为克服上述挑战，VLA模型合成数据领域的研究正积极探索以下策略：

- **增强模拟器保真度与物理准确性：** 需要开发更先进的物理引擎和渲染技术，以实现更高保真度的模拟。例如，AutoBio通过数字化真实仪器、开发螺纹和准静态液体等专业物理插件以及基于物理渲染（PBR）技术，显著提高了生物实验室环境模拟的准确性 15。这种精细化的物理建模对于VLA模型学习复杂操作至关重要。
    
- **改进域随机化与自适应学习：** 结合更智能的域随机化策略和自适应学习方法，使模型能够更好地从合成数据泛化到真实世界。例如，RoboTwin 2.0通过在杂乱度、照明、背景、桌面高度和语言指令等多个维度上进行结构化随机化，迫使模型学习更具普适性的特征，从而显著提高了真实世界泛化能力 6。
    
- **混合数据训练：** 将少量高质量真实数据与大规模合成数据结合进行训练，以弥补纯合成数据的不足 7。真实数据可以为模型提供关键的真实世界分布信息，而合成数据则可以提供多样性和规模。
    
- **在线强化学习与人类干预：** 利用在线强化学习（RL）和人类干预来微调VLA模型，提高其在真实世界中的性能和样本效率。例如，ConRFT通过结合行为克隆（BC）损失和Q学习进行离线预训练，再通过在线RL和人类干预进行微调，有效解决了真实世界演示数据有限且不一致的问题，显著提升了模型在真实操作任务中的成功率 41。
    
- **世界模型与预测性学习：** 进一步发展世界模型，使其能够更准确地预测未来状态，从而支持更复杂的规划和决策。例如，3D-VLA模型通过整合3D感知、推理和动作的生成式世界模型，能够预测目标图像和点云 30。LaDi-WM则通过预测未来状态的潜在空间来指导动作优化，提高了预测性操作的准确性和泛化能力 35。
    

### 4.3. 未来研究方向

VLA模型合成数据领域正处于快速发展阶段，未来的研究方向将集中于以下几个方面：

- **更智能的合成数据生成器：** 结合大型语言模型（LLMs）和扩散模型，实现更自主、更具创造力的合成数据生成。这将不仅仅是生成指令或视觉场景，而是能够生成新颖的任务、环境和交互模式，甚至能够模拟复杂社会场景中的人类行为 46。这将极大地扩展VLA模型训练数据的广度和深度。
    
- **多模态数据一致性与对齐：** 解决视觉、语言和动作数据之间的时间和语义一致性问题，确保合成数据的内部逻辑连贯性。这将涉及开发更先进的标注和验证工具，以及能够自动检测和纠正数据中不一致性的算法 40。
    
- **跨具身泛化：** 探索如何生成能够促进VLA模型在不同机器人平台和形态之间迁移技能的合成数据。这将有助于构建更通用的机器人策略，减少为每种新机器人硬件重新收集数据的需求 6。
    
- **可解释性与可信赖AI：** 随着VLA模型在关键应用中的部署，开发能够解释合成数据生成过程和模型决策的方法将变得至关重要。这将提高VLA系统的透明度和可信赖性，促进其在安全敏感领域的应用。
    
- **物理定律的深度整合：** 进一步将复杂的物理定律和材料属性深度整合到模拟器和生成模型中，以确保合成数据的物理真实感达到更高水平，从而更好地弥合模拟与现实之间的差距。
    

## 5. 结论

VLA模型是具身智能发展的关键，它们对大规模、高质量、多模态数据的需求是其复杂性和通用性目标的直接体现。然而，真实世界数据收集的固有挑战使得合成数据成为弥合“数据鸿沟”和实现“通用具身智能”的战略性解决方案。

本报告详细阐述了VLA模型合成数据的主要方法：

- **基于模拟器的环境与交互生成**通过程序化生成、数字孪生和物理仿真，为VLA模型提供了无限多样、物理精确的训练场景和具身交互数据，如PhysicsGen、AutoBio和EmbodiedGen等案例所示，这些方法显著提升了模型的视觉感知和精细操作能力。
    
- **基于大型语言模型（LLM）的指令与规划生成**通过自然语言指令与任务分解、逻辑形式与行为序列合成以及奖励函数与高层规划，弥合了人类意图与机器人动作之间的语义鸿沟，确保了合成指令的精确性和可验证性，并克服了强化学习中的稀疏奖励挑战。
    
- **基于扩散模型的视觉与动作合成**通过轨迹生成与预测、世界模型与未来状态预测以及神经轨迹与行为泛化，极大地丰富了VLA模型的动作空间和泛化能力，实现了零样本行为和环境泛化，并转变了机器人学习的数据扩展范式。
    

数据增强和域随机化策略是弥合“现实差距”的核心手段，通过系统性地模拟真实世界的复杂性和变异性，主动缩小了模拟与现实之间的差距，显著提升了VLA模型在未见场景和指令下的泛化能力，RoboTwin 2.0的成功实践提供了有力的量化证据。

尽管VLA模型合成数据领域取得了显著进展，但“现实差距”和数据一致性问题（如偏置的时间分布、不精确的标注、不足的组合性、不一致的演示）仍然是重要挑战。未来的研究应聚焦于开发更智能的合成数据生成器、解决多模态数据一致性与对齐问题、实现跨具身泛化，并增强VLA系统的可解释性与可信赖性，同时深度整合物理定律。通过持续创新和多学科交叉，合成数据将继续作为推动VLA模型从实验室走向实际应用，实现真正通用具身智能的核心驱动力。