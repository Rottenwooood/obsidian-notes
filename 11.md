deep research
# VLA（视觉-语言-动作模型）合成数据进展报告 (2023-2025)

## 1. 引言

### VLA模型概述及其对合成数据的需求

视觉-语言-动作（Vision-Language-Action, VLA）模型代表了人工智能领域的一项变革性进展，旨在将感知、自然语言理解和具身动作无缝整合到统一的计算框架中。这些模型的核心目标是赋予通用型机器人感知环境、理解复杂人类指令并动态执行适当行动的能力，从而使其能够在现实世界中灵活运作 1。VLA模型的早期探索始于2021-2022年，通过扩展现有的视觉-语言模型以纳入动作令牌，奠定了从配对的视觉、语言和机器人轨迹数据中学习的基础 1。

VLA模型的持续发展和规模化部署，对大规模、多样化和高质量数据集的依赖性极高。然而，现实世界中机器人数据的收集面临诸多挑战：它不仅成本高昂、劳动密集、耗时漫长，而且所能获得的数据集在范围和多样性上往往受限，尤其难以捕捉对构建鲁棒AI系统至关重要的稀有或危险场景 3。这种现实世界数据的稀缺性，已成为制约VLA模型泛化能力和广泛应用的关键瓶颈 2。

面对这些挑战，合成数据已成为一种不可或缺、经济高效且可扩展的替代方案 3。通过人工生成模仿现实世界观察特征的数据，合成数据能够提供海量且高度多样化的视觉、语言和动作数据。这使得研究人员能够根据特定场景和难以在现实环境中捕捉的边缘案例定制数据，从而显著提升模型的鲁棒性、泛化能力以及VLA系统的安全性 5。这种从现实数据稀缺性到合成数据依赖的转变，正在加速VLA模型的发展，使其能够处理更复杂的任务并向通用型机器人迈进。

### 报告范围与结构

本报告旨在全面总结2023年至2025年间，视觉-语言-动作（VLA）模型在机器人和具身AI领域合成数据生成方法方面的最新进展。报告将系统性地探讨合成数据生成的主要方向，包括基于仿真环境的生成、利用先进AI生成模型（如扩散模型、变分自编码器和生成对抗网络）以及智能数据扩增技术。此外，报告还将重点介绍合成数据在VLA模型能力提升中的关键应用案例，并最终讨论该快速发展领域中持续存在的挑战和充满前景的未来研究方向。

## 2. 合成数据生成的主要方向

VLA模型合成数据生成领域呈现出多种方法融合的趋势，每种方法都在解决固有数据挑战方面发挥着独特作用。这些方向涵盖了从高度受控的仿真环境到先进的AI驱动生成模型，再到智能数据扩增技术。

### 2.1 仿真环境生成

仿真作为合成数据生成的基础，为VLA模型的训练提供了可扩展、可控且经济高效的环境。

#### 物理仿真与虚拟环境

现代仿真平台利用高保真物理引擎（例如PyBullet、MuJoCo、CoppeliaSim、NVIDIA Omniverse和Unity）精确模拟物理交互，包括摩擦、接触和碰撞。这些环境使研究人员能够设计低成本、可控的训练设置，支持在各种场景下生成大量数据 4。

一个值得关注的例子是**Buildee**，一个基于Blender构建的3D仿真框架。它专门用于基准测试场景探索、3D重建和语义分割任务，涵盖静态和动态环境。Buildee能够生成逼真的RGB、深度和语义数据，并支持2D/3D点跟踪和遮挡检测，为评估场景理解算法提供了一个标准化平台 10。这突显了仿真在提供VLA感知所需丰富多模态数据方面的能力。

#### 领域随机化与数据多样性

为了增强VLA模型在合成数据上训练后的现实性和泛化能力，领域随机化是一项关键技术。这涉及在仿真环境中系统性地改变视觉和物理属性，例如光照、纹理、物体形状、材料和摄像机视角 3。其目标是创建足够多样化的合成数据分布，以覆盖现实世界中遇到的变异性，从而提高学习策略的可迁移性。

**GraspVLA**通过其**SynGrasp-1B**数据集体现了这一方法，这是一个十亿帧的合成机器人抓取数据集。该数据集完全在仿真中生成，结合了光真实感渲染和广泛的领域随机化。它利用了庞大的物体资产库（来自Objaverse的240个类别，10,680个实例），通过随机缩放和姿态生成多样化且物理上合理的场景，以训练可泛化的抓取基础模型 3。

#### Sim-to-Real 迁移学习

尽管仿真保真度不断提高，但“Sim-to-Real差距”仍然是一个严峻的挑战，即在仿真器中训练的模型在部署到现实物理环境时性能会下降 4。研究人员正在积极开发先进技术来弥合这一差距，确保从仿真数据中获得的洞察能够有效地转化为现实世界应用。

**ReBot**提出了一种新颖的“real-to-sim-to-real”（从现实到仿真再到现实）方法，旨在扩展真实机器人数据集并使VLA模型适应目标领域 6。该方法包括在仿真中重放真实机器人轨迹以多样化被操作的物体（从现实到仿真），然后将模拟运动与修复后的真实世界背景相结合，以合成物理上真实且时间上一致的机器人视频（从仿真到现实）。ReBot的核心优势在于通过将动作和观察空间都基于真实数据来最小化Sim-to-Real差距，同时利用仿真的可扩展性 7。大量实验表明，ReBot显著增强了VLA模型在仿真和现实环境中的性能和鲁棒性 6。

仿真策略的演进呈现出从简单生成到复杂Sim-to-Real管道的明显趋势，这主要受VLA模型泛化需求的驱动。最初，合成数据的目标仅仅是创建更多数据。然而，随着VLA模型日益复杂以及对鲁棒现实世界部署的需求增长，简单仿真的局限性变得显而易见。这种局限性促使了领域随机化和real-to-sim-to-real等更复杂方法的发展，这些方法旨在提高在合成数据上训练的模型泛化能力。未来的进展将继续专注于通过日益精细和自适应的仿真技术来缩小这一差距，从而实现不仅视觉上令人信服，而且在物理和行为上也足够准确的合成数据，以实现无缝的现实世界迁移。

### 2.2 AI生成模型

深度生成模型通过学习真实数据的底层分布并生成全新、逼真的实例，彻底改变了合成数据生成。这些模型在解决数据稀缺性问题和实现VLA模型更鲁棒的评估方面发挥着关键作用 18。

#### 扩散模型 (Diffusion Models)

扩散模型已成为一种极其强大且通用的生成式AI技术，在生成高保真和多样化样本方面表现出突破性性能，通常超越了早期最先进的模型，如GANs和VAEs 19。其操作原理涉及两个步骤：逐步向数据添加噪声（前向扩散），然后学习逆转这一过程，通过逐渐去除噪声来恢复原始数据 19。对于VLA而言，一个关键优势是它们能够通过整合特定的条件信息来生成条件样本 19。

**在VLA中的应用：** 扩散模型越来越多地用于合成逼真的机器人动作轨迹和视觉观察。例如，**GIFT**（Generated data to Improve continual Fine-Tuning）利用预训练的扩散模型（如Stable Diffusion）动态地重建预训练数据和先前学习的下游任务数据。这种创新方法通过在这些合成图像-文本对上进行蒸馏，帮助VLM（视觉-语言模型）克服灾难性遗忘，实现持续学习 20。Stable Diffusion动态再生的低计算成本确保了多样性，而无需大量的存储需求 20。

**动作生成：** 扩散模型也直接应用于动作生成。**Diffusion Policy**（Chi et al., 2023）是利用扩散过程的紧凑动作模型的一个显著例子 21。此外，

**UniVLA**将视觉、语言和动作信号建模为离散令牌序列，并在后训练期间整合世界模型学习，以有效捕捉大规模视频中的视觉动态。该策略显著提高了下游策略学习的数据和训练效率，表明合成视频数据在其中发挥着关键作用 22。

#### 变分自编码器 (Variational Autoencoders - VAEs)

VAEs采用编码器-解码器架构，其中编码器将输入数据映射到压缩的潜在空间，捕捉其底层分布，然后解码器从该表示中重建输入。VAEs以促进生成样本的高度多样性而闻名，尽管由于其基于像素的损失函数，它们在历史上与生成模糊输出相关联，相比GANs保真度较低 18。最近的进展主要集中于提高其保真度和效率。

**在VLA中的应用：** VAEs通过在压缩潜在空间中训练生成模型来提高生成模型的质量和效率 23。离散潜在方法，如

**向量量化变分自编码器（VQ-VAEs）**，尤其相关，因为它们通过掩码或自回归Transformer实现基于令牌的视频生成 23。

**示例：** **VQ-VLA**引入了一种创新的基于向量量化的动作分词器，该分词器基于迄今为止最大规模的动作轨迹数据集构建，利用的数据量是先前方法的100多倍 24。通过利用VQ-VAEs，VQ-VLA能够捕捉丰富的时空动态，从而使VLA模型能够加速推理并生成更平滑、更连贯的动作输出 24。一个关键发现是，合成动作轨迹与真实动作轨迹之间的领域差距微乎其微，这使得在训练过程中可以有效利用大量合成数据 24。VQ-VLA采用渐进式训练策略，从真实世界数据开始，逐步整合来自模拟数据集的更干净的合成数据，以趋向更平滑、更稳定的表示 25。

#### 生成对抗网络 (Generative Adversarial Networks - GANs)

GANs由两个相互竞争的神经网络组成：一个生成器负责创建模仿真实样本的数据，一个判别器负责评估数据的真实性。这种对抗过程驱动生成器产生极其逼真的输出，使GANs以生成高保真样本而闻名。然而，GANs可能面临训练不稳定和模式坍塌的问题，这会限制生成样本的多样性 18。

**在VLA中的应用：** 尽管提供的资料并未详细说明2023-2025年间GANs在VLA“动作”生成方面的具体模型，但GANs被广泛认为是机器人和计算机视觉领域合成数据的基本生成模型范式 3。机器人操作中生成模型的更广泛背景包括GANs在改进场景理解和任务规划方面的应用 4。像

**GraspVLA**这样利用合成数据进行操作的模型所取得的成功，突显了AI生成数据的普遍潜力，即使其动作生成的具体机制是流匹配而非GANs 3。

#### 大型语言模型在数据生成中的应用 (LLMs in Data Generation)

大型语言模型（LLMs）凭借其数十亿参数和对海量文本语料库的训练，能够生成高质量、连贯且与人类书写内容高度相似的文本。至关重要的是，LLMs可以通过提示词指导生成特定任务的数据，从而有效地充当高度灵活的通用数据扩增器，按需为广泛的问题创建带标签数据 8。

**在VLA中的应用：** LLMs越来越多地被整合到VLA模型中，用于高层次的推理、规划和决策 5。虽然它们可能不像扩散模型那样直接生成原始视觉或动作数据，但它们可以定义复杂的场景、提供详细指令或强制执行语义和安全约束，从而协调和指导合成数据生成过程。例如，一个新颖的多智能体框架利用LLM智能体（“评估智能体”和“编辑智能体”）进行迭代协作，以在安全关键AI系统的高保真场景生成过程中强制执行语义一致性和安全特定约束 5。这表明LLMs在创建结构化、上下文丰富的合成数据方面的作用。

生成式AI模型在VLA合成数据领域的核心地位日益凸显，每种模型都为不同的数据模态和任务提供了独特的优势。扩散模型在高保真图像和动作生成方面表现出色，变分自编码器（特别是VQ-VAEs）在高效动作分词和潜在表征方面发挥关键作用，而大型语言模型则在提供多样化语言指令和语义指导方面至关重要。

生成模型的发展趋势明显地体现在对VLA特定挑战的应对上，例如通过GIFT模型中的扩散模型来解决灾难性遗忘问题，以及通过VQ-VAEs进行动作分词来提高计算效率。这表明生成模型不仅仅是为了提供“更多数据”，更是为了提供“更智能、更高效的数据”，以适应VLA模型的固有局限性。

大型语言模型在VLA模型合成数据生成中的作用日益增强，这标志着合成环境中对语义丰富性和任务特定指导的重视不断提高，从而弥合了高层次语言理解与低层次动作生成之间的鸿沟。LLMs能够生成反事实数据并推断重构配置，这使得数据扩增具有语义上的丰富性，超越了简单的排列组合。这种由LLMs和3D数据促成的语义和空间感知相结合，使得生成的合成数据不仅多样化，而且是“智能多样化”的，直接影响了VLA模型在复杂、未见环境中进行推理和行动的能力。

### 2.3 数据扩增技术

数据扩增（Data Augmentation, DA）技术在人工增加训练数据集的规模和多样性方面发挥着至关重要的作用，有效缓解了真实世界数据有限的问题，提高了模型泛化能力并增强了鲁棒性 28。传统的DA方法涉及简单的变换，但现代方法越来越多地利用生成模型和语义理解来实现更复杂、更真实的扩增 8。

#### 传统图像与动作序列扩增

基本的图像变换，如旋转、平移、裁剪和翻转，长期以来一直是计算机视觉领域的标准实践 30。这些方法对现有数据引入细微变化，帮助模型对小扰动变得更加鲁棒。对于VLA模型，类似的原理也适用于视觉观察，并可以扩展到动作序列的简单操作。

例如，在图像分类的更广泛背景下，旋转、水平或垂直翻转以及亮度调整已被确定为提高模型准确性的有效扩增技术 31。尽管这些例子来自射电天文学，但其底层技术可以直接应用于VLA模型的视觉组成部分。

#### 基于因果关系与语义的智能扩增

除了简单的几何变换，更先进的扩增方法深入挖掘数据的语义和因果结构，以生成更有意义的变体。例如，**反事实数据扩增**（Counterfactual data augmentation）在数据因果结构的指导下进行。它可以模拟对虚假特征的干预，从而学习到对不相关关联不那么敏感的更鲁棒的分类器 32。这对于多模态VLA数据尤其相关，因为视觉、语言和动作之间的复杂交互可能导致虚假关联。

大型语言模型（LLMs）和其他生成模型越来越多地被用于此目的，从而能够创建涉及对混淆因素或标签进行有针对性扰动的反事实实例 32。这使得扩增从表面变化转向深度、语义驱动的数据生成。

#### 合成演示生成与空间泛化

对于机器人和VLA模型而言，生成合成演示是一种强大的扩增策略，直接解决了收集多样化真实世界机器人轨迹的高成本问题。

**DemoGen**是一种低成本、完全合成的自动演示生成方法 10。其独特之处在于，它仅需要每个任务的一个人类收集的演示，然后通过将演示的动作轨迹适应新的物体配置来生成空间增强的演示。经验表明，这种方法显著提高了策略性能和空间泛化能力，适用于各种真实世界操作任务，包括涉及可变形物体、灵巧手末端执行器和双臂平台的操作 33。一个关键的技术方面是，它利用3D点云编辑作为观察模态来合成增强的视觉观察，从而利用点云固有的3D结构进行有效操作 33。

数据扩增在VLA模型中的应用已从简单的变换发展到复杂、上下文感知的技术，这些技术能够增强模型的空间泛化能力和鲁棒性。LLMs和3D表征的整合对于生成VLA复杂任务所需的高质量、多样化和上下文相关合成数据至关重要。例如，LLMs生成反事实数据和推断重构配置的能力，使得扩增具有语义上的丰富性，超越了简单的排列组合。DemoGen对点云和3D编辑的使用，利用了环境的几何理解。这种由LLMs和3D数据促成的语义和空间感知相结合，使得生成的合成数据不仅多样化，而且是“智能多样化”的，直接影响了VLA模型在复杂、未见环境中进行推理和行动的能力。

合成演示生成（如DemoGen）标志着获取专家行为的编程化和数据高效方式的转变，减少了对特定任务变体昂贵的人类演示的依赖。人类收集演示的高成本是主要瓶颈。DemoGen通过仅使用一个人类演示，并以编程方式生成“空间增强”版本来解决这个问题。这是自动化模仿学习数据收集过程的重要一步，使得训练VLA模型能够应对更广泛的任务和配置，而无需承担高昂的真实世界数据获取成本。

### 表1：VLA模型关键合成数据生成方法 (2023-2025)

|方法类别|机制/关键原理|典型VLA应用|优点|缺点/挑战|相关模型/研究 (示例)|
|---|---|---|---|---|---|
|**仿真环境**|利用高保真物理引擎在虚拟环境中模拟物理交互和场景。|大规模数据集创建、多样化场景生成、边缘案例测试。|成本效益高，可控性强，可扩展性强，可生成多样化数据。|存在Sim-to-Real差距，难以完全复制现实世界复杂性。|Buildee 13, SynGrasp-1B 3, ReBot 7|
|**扩散模型**|通过逐步添加和移除噪声来学习数据分布并生成高保真样本。|视觉观测和动作轨迹的生成，持续学习中的知识保持。|生成样本高保真、多样性强，支持条件生成。|计算量大，采样速度相对较慢。|GIFT 20, Diffusion Policy 21, UniVLA 22|
|**变分自编码器 (VAEs)**|编码器将数据映射到潜在空间，解码器从该空间重建，促进样本多样性。|动作序列的量化和压缩，提高推理效率和动作连贯性。|训练过程相对稳定，生成样本多样性好，可用于高效的动作表征。|传统VAEs可能生成模糊图像，保真度可能低于扩散模型。|VQ-VLA 24|
|**生成对抗网络 (GANs)**|生成器和判别器对抗学习，生成逼真数据。|场景理解和任务规划中的数据增强，生成逼真图像。|擅长生成高保真、锐利的图像。|训练不稳定，易出现模式坍塌，多样性可能受限。|- (在VLA动作生成中未明确提及2023-2025具体模型) 4|
|**大型语言模型 (LLMs) 指导生成**|LLMs通过提示词理解和生成文本，并指导其他模型生成多模态数据。|复杂场景定义、指令生成、语义约束、安全关键场景生成。|能够提供高层次的语义指导和上下文，生成任务特定数据。|不直接生成原始视觉/动作数据，依赖与其他生成模型的结合。|多智能体框架 5, EvolveNav 35|
|**高级数据扩增 (如合成演示)**|通过对现有数据进行智能操作或生成新变体，以增强空间泛化和鲁棒性。|减少对人类演示的依赖，提高策略对新配置的泛化能力。|成本效益高，可实现高效的数据获取，增强模型对未见场景的适应性。|需要领域知识指导，可能引入新的领域差距。|DemoGen 33|

## 3. VLA模型中合成数据的应用案例与进展

合成数据已成为推动VLA模型在各种机器人和具身AI应用中突破界限的关键，使其能够实现仅凭真实世界数据无法实现的能力。

### 机器人抓取与操作

合成数据对于训练机器人操作（如抓取）的通用基础模型至关重要，因为这些任务需要接触极其多样化的物体、环境和交互条件 3。

- **GraspVLA：** 这是一个开创性的基础VLA模型，完全在光真实感渲染和广泛领域随机化下的仿真环境中，利用大规模合成动作数据（十亿帧的**SynGrasp-1B**数据集）进行预训练 3。GraspVLA将自回归感知任务与流匹配（flow-matching）动作生成相结合，实现了合成动作数据和互联网语义数据的联合训练。一个关键成就是，它展示了直接的Sim-to-Real迁移和对真实世界抓取任务的强大零样本泛化能力，无需在真实数据上进行微调，并取得了高成功率（例如，零样本成功率85%，微调后提高到95%） 14。这项工作显著强调了合成数据在训练用于操作的VLA模型方面的巨大潜力 3。
    
- **DemoGen：** 该系统提供了一种低成本、完全合成的自动演示生成方法，直接解决了视觉运动策略学习中数据密集型的问题 10。DemoGen通过仅使用每个任务的一个人类收集的演示，然后通过将演示的动作轨迹适应新的物体配置，生成空间增强的演示。经验表明，这种方法显著提高了策略性能和空间泛化能力，适用于各种真实世界操作任务，包括涉及可变形物体、灵巧手末端执行器和双臂平台的操作 33。值得注意的是，DemoGen利用3D点云编辑作为其观察模态，以合成增强的视觉观察，从而利用点云固有的3D结构进行有效操作 33。
    
- **VQ-VLA：** 该模型引入了一种创新的基于向量量化的动作分词器，该分词器基于迄今为止最大规模的动作轨迹数据集构建，利用的数据量是先前方法的100多倍 24。通过利用VQ-VAEs，VQ-VLA能够捕捉丰富的时空动态，从而使VLA模型能够加速推理并生成更平滑、更连贯的动作输出。一个关键发现是，合成动作轨迹与真实动作轨迹之间的领域差距微乎其微，这使得在训练过程中可以有效利用大量合成数据，从而在真实世界长时任务中成功率提高达30% 24。这展示了合成数据在扩展动作分词器以实现高效可靠机器人控制方面的强大能力。
    

### 具身导航与推理

VLA模型越来越多地应用于具身导航和推理任务，使智能体能够理解其环境、解释指令并规划复杂3D空间中的动作 1。合成数据为训练这些能力提供了必要的规模和多样性。

- **UP-VLA：** 这一统一的VLA模型探索了一种新颖的训练范式，结合了多模态理解和未来预测目标 21。通过强调高层次语义理解和低层次空间理解，UP-VLA在CALVIN等仿真环境中，针对长时语言条件任务，表现出显著的性能提升 21。将视觉预测整合到VLA框架中尤为有效，它增强了模型在强调视觉泛化任务中的性能 37。该模型的成功突显了合成数据，特别是针对预测任务的合成数据，如何推动鲁棒的具身推理。
    
- **Buildee：** 尽管Buildee本身不是VLA模型，但它是一个关键的3D仿真框架，为训练和评估具身导航和推理模型提供了必不可少的合成环境和数据 10。它允许对场景探索、3D重建和语义分割进行基准测试，这些都是VLA智能体在3D世界中操作的基础能力。其程序化生成能力能够创建多样化且复杂的环境，例如建筑工地，以实现鲁棒的模型训练 13。
    
- **EvolveNav：** 这种基于LLM的VLM方法侧重于具身导航的自改进推理 35。通过使用形式化的思维链（Chain-of-Thought, CoT）标签进行训练，并采用自反思后训练机制，EvolveNav在未见导航场景中显著优于先前的基于LLM的VLN（视觉-语言导航）方法。这表明合成数据（CoT标签、自生成数据）在提高导航任务泛化能力和推理速度方面的关键作用 35。
    

### 多模态理解与预测

VLA模型致力于实现统一的多模态智能，整合来自视觉、语言和行为模态的信息，通常利用结合这些数据类型的大规模数据集 1。合成数据在扩增、多样化和维护这些复杂多模态输入方面发挥着关键作用。

- **GIFT：** 这种方法专门解决了视觉-语言模型（VLMs）在持续学习中灾难性遗忘的挑战，通过利用合成数据实现 20。GIFT使用预训练的扩散模型（如Stable Diffusion）生成合成图像-文本对，以重建原始预训练数据和先前学习的下游任务数据。通过结合对比蒸馏损失和图像-文本对齐约束，GIFT有助于保持VLM特征空间的完整性，并确保鲁棒的知识保留 20。这展示了合成数据的一种新颖应用，不仅用于初始训练，还用于动态知识维护和多模态理解能力的增强。
    
- **UniVLA：** UniVLA被视为一个统一的原生多模态VLA模型，它将视觉、语言和动作信号自回归地建模为共享词汇表中的离散令牌序列 22。这种公式化促进了灵活的多模态任务学习，特别是从大规模视频数据中学习。该模型在后训练期间整合了世界模型学习，使其能够有效捕捉视频中的视觉动态。该策略显著提高了下游策略学习的数据和训练效率，尤其适用于长时和分布外场景，表明其对合成视频数据的强烈依赖和受益 22。
    
- **ReBot：** 除了其在Sim-to-Real迁移中的作用外，ReBot的“real-to-sim-to-real”方法通过将模拟运动与修复后的真实世界背景相结合，有效地合成了物理上真实且时间上一致的机器人视频 7。这个过程生成了高质量的多模态数据（视觉观察、隐含动作及其时间关系），这对于训练VLA模型理解和预测复杂的现实世界交互至关重要。创建这种受控但逼真的多模态序列的能力，对于开发能够对动态环境进行推理的VLA模型至关重要。
    

合成数据正在推动VLA模型向“通用型”发展，并实现零样本迁移。例如，GraspVLA通过大规模合成动作数据预训练，实现了直接的Sim-to-Real迁移和强大的零样本泛化能力，在没有真实世界训练的情况下，在真实世界抓取任务中取得了85%的成功率。VQ-VLA也指出，合成动作轨迹与真实动作轨迹之间的领域差距微乎其微，并且随着合成数据量的增加，真实世界任务的性能显著提高。这些成果表明，合成数据提供了必要的广度和深度经验，使模型能够泛化到其初始训练分布之外。这标志着机器人学习范式的深刻转变，从针对特定任务的训练转向基础模型，这些模型能够以最少或无需真实世界微调的方式适应新任务和环境，从而加速机器人技术的部署并扩大其适用范围。

合成数据在持续学习中扮演着“记忆辅助”和“知识精炼器”的角色。例如，GIFT模型明确利用合成数据来克服VLM在持续学习中的灾难性遗忘问题，方法是让VLM通过对扩散模型生成的图像和相应文本提示进行蒸馏来“重温”先前的知识。这揭示了合成数据更深层次的作用：它不仅仅用于初始训练或扩展数据集，还可以作为模型随时间推移保持知识的动态“记忆”或“排练机制”。通过合成过去的数据分布，它允许模型持续强化已学知识，而无需存储或重新访问大量的原始真实世界数据。这种能力对于在动态环境中持续学习和适应而不遗忘旧技能的长期、自主具身AI系统至关重要。

### 表2：利用合成数据的VLA模型案例 (2023-2025)

|模型名称|主要任务/领域|合成数据方法|关键成果 (含指标)|相关文献|
|---|---|---|---|---|
|**GraspVLA**|机器人抓取与操作|大规模仿真数据 (SynGrasp-1B)，光真实感渲染与领域随机化。|零样本泛化到真实世界抓取任务，无需微调，成功率达85% (零样本)，微调后达95%。|3|
|**DemoGen**|机器人操作 (视觉运动策略学习)|合成演示生成，基于人类演示轨迹的空间增强，3D点云编辑。|显著提升策略性能和空间泛化能力，适用于多种真实世界操作任务。|33|
|**VQ-VLA**|机器人操作 (动作序列表征)|基于VQ-VAE的动作分词器，利用大规模合成轨迹数据。|加速推理，生成更平滑连贯的动作输出，在真实世界长时任务中成功率提高30%。|24|
|**UP-VLA**|具身导航与推理|多模态理解与未来预测目标训练，仿真环境评估。|在CALVIN ABC->D基准测试中性能提高33%，在真实世界操作任务中成功率提高。|21|
|**GIFT**|VLM持续学习|利用预训练扩散模型生成合成图像-文本对。|克服灾难性遗忘，通过蒸馏保持VLM特征空间完整性，实现鲁棒知识保留。|20|
|**UniVLA**|多模态VLA统一建模|视觉、语言、动作信号离散分词，世界模型学习，大规模视频数据。|灵活的多模态任务学习，提高数据和训练效率，尤其适用于长时任务。|22|
|**EvolveNav**|具身导航与推理|LLM引导的CoT标签，自反思后训练。|在未见导航场景中显著优于现有LLM-based VLN方法。|35|
|**ReBot**|机器人学习 (数据扩展与适应)|Real-to-sim-to-real 机器人视频合成，结合模拟运动与真实背景。|显著增强VLA模型在模拟和真实环境中的性能和鲁棒性。|7|

## 4. 挑战与未来展望

尽管VLA模型合成数据生成取得了显著进展，但仍存在一些重大挑战，需要持续的研究和创新才能充分发挥具身AI的潜力。

### 4.1 现实差距与数据保真度

“Sim-to-Real差距”仍然是将仿真环境中训练的VLA模型部署到现实物理环境中的一个巨大障碍 16。这种差异可能体现在动作空间（模拟动作转化为真实机器人运动的准确性）和观察空间（合成视觉数据捕捉现实世界感知的细微差别的能力）7。

尽管ReBot等方法通过“real-to-sim-to-real”管道取得了进展，但生成模型在提供物理上真实且时间上一致的机器人视频方面仍面临挑战 7。合成过程中引入的失真可能会产生新的领域差距，使得VLA模型难以学习稳定和连续的机器人动作 7。确保合成数据的“真实性”和“多样性”是一个持续的挑战 38。虽然扩散模型在保真度方面表现出色，但它们可能计算量大且速度慢 3。GANs可能出现模式坍塌，限制多样性 3，而VAEs可能生成模糊图像 3。

“现实差距”是一个不断演变的挑战，需要持续创新来弥合。随着合成数据生成变得更加复杂（例如，光真实感、复杂物理），合成数据与真实数据之间细微的差异变得更加微妙，需要日益先进的技术来弥合它们。这意味着未来的研究不仅要关注生成“更多”数据，还要关注生成在所有相关方面与真实数据“感知和物理上无法区分”的数据，以及能够处理剩余领域偏移的鲁棒迁移学习方法。这对于安全关键应用至关重要，在这些应用中，即使是微小的误差也可能产生重大后果。

### 4.2 伦理考量与偏见缓解

合成数据，特别是通过生成式AI生成的数据，带来了独特的伦理挑战 39。

- **误报与隐私：** 存在合成数据被误认为是真实数据的风险，这可能破坏研究记录并损害科学的完整性 39。故意伪造或篡改数据是更难处理的问题 39。虽然合成数据可以通过避免敏感个人信息来减少隐私问题，但如果安全措施不健全，合成数据可能包含可用于重建其所基于的私人数据的信息 42。
    
- **偏见放大与有害行为：** 如果用于生成合成数据的模型和算法未经过仔细验证和测试，合成数据可能会延续和放大训练数据中存在的偏见 42。这对于与多样化人类用户或环境交互的VLA模型尤为重要。VLM可能产生有害行为，这对于VLM控制的与世界交互的机器人来说尤其危险。实施行为保障措施可能会限制其功能和伦理范围 43。存在“双重用途困境”，即在民用领域有用的能力可能在军事领域有害 43。
    
- **缓解策略：** 建议期刊、资助机构或学术机构制定相关指南 39。对合成数据进行水印处理有助于识别 39。在研究中进行负责任行为的教育和指导是必要的 41。
    

伦理治理和鲁棒验证对于VLA中可信赖的合成数据至关重要。多个研究强调了与合成数据相关的“伦理挑战”，包括误报、隐私和偏见。对于VLA而言，与物理世界交互的机器人可能产生“有害行为”和“双重用途困境”，这是直接的后果。VLA模型中合成数据日益增长的真实性和部署，直接放大了这些伦理风险。如果用于训练的合成数据存在偏见，或者基于合成数据训练的模型表现出有害的涌现行为，VLA系统在现实世界中的影响可能是负面的。这意味着合成数据生成的技术进步必须伴随着鲁棒的伦理框架、验证协议和监管考量。重点从仅仅“生成”数据转向“负责任地生成和使用”数据，确保VLA模型不仅有能力，而且安全、公平并符合人类价值观。这需要跨学科的努力，而不仅仅是AI研究人员的努力。

### 4.3 计算效率与可扩展性

下一代望远镜和调查（如SKA）将产生海量数据（9-20 TB/秒），使得传统处理和存储变得不可行 45。这需要具备HPC（高性能计算）能力的机器学习驱动的自动化决策系统 46。

尽管扩散模型提供了高保真度和多样性，但它们计算量大且比GANs和VAEs慢，需要多次迭代 47。射电干涉成像方法通常难以处理大量数据，并且计算成本高昂，特别是对于不确定性量化 38。

数据量和计算成本是相互交织的制约因素。新一代系统（如SKA，以及更复杂的VLA模型）生成“海量”数据。处理这些数据“计算量大”、“成本高昂”，并需要“HPC能力”的系统。数据量的巨大使得传统方法无法扩展，从而推动了对更高效AI处理的需求。然而，最先进的AI生成模型（如扩散模型）本身就是计算密集型的。这形成了一个反馈循环，即数据量的增加需要更强大的AI，而AI又反过来需要更多的计算资源。

这意味着未来的研究必须专注于开发更“计算高效”的合成数据生成方法和VLA架构（例如，潜在空间模型、扩散模型的优化采样），以跟上数据指数级增长的步伐，从而实现实时处理和在资源受限环境中的部署。这也突显了专用硬件和分布式计算的重要性。

### 4.4 开放性问题与研究方向

- **统一框架：** 开发更深度集成的框架，使VLM和更广泛的计算环境（操作系统、API、网络浏览器）作为一个内聚系统运行，学习与系统级功能进行原生交互 27。
    
- **鲁棒接地与长时规划：** 实现语言与计算动作的鲁棒接地，以及能够进行长时规划和在复杂软件生态系统中交互的模型 27。
    
- **伦理保障：** 持续研究LLM/VLM驱动机器人的实时监控、对抗鲁棒性和伦理保障 44。
    
- **减少数据依赖：** 进一步减少对少量初始真实世界演示的依赖，以进行合成数据生成 6。
    
- **改进物理真实感和时间一致性：** 增强生成模型以持续提供物理上真实且时间上一致的机器人视频 7。
    
- **解决VLA的上下文学习：** 将上下文适应性注入预训练的VLA中，以允许在不进行参数调整的情况下轻松改进，利用少量机器人演示数据集 48。
    
- **3D空间理解：** 克服现有VLA模型在精确3D空间理解方面的致命局限性，这通常归因于预训练中的2D图像-文本对齐和缺乏明确3D信息的少量机器人数据集 2。目前正在出现整合3D信息（例如，点云、深度图）的方法 2。
    
- **神经科学启发式增强：** 综合神经科学和先进AI的见解，以增强预训练的VLA模型，这与神经AI的动机相符 49。
    

## 5. 结论

在2023年至2025年间，合成数据在推动视觉-语言-动作（VLA）模型发展方面发挥了不可或缺的作用。仿真环境生成、AI生成模型（特别是扩散模型和变分自编码器）以及高级数据扩增技术，共同构成了VLA模型数据供给的支柱。这些方法有效地缓解了真实世界数据收集的固有成本和局限性，使得训练通用型、鲁棒性强的具身智能体成为可能。

通过大规模仿真数据集（如SynGrasp-1B）的预训练，VLA模型已展现出卓越的零样本泛化能力和直接的Sim-to-Real迁移效果，显著加速了机器人抓取和操作任务的部署。同时，扩散模型在持续学习中通过动态生成合成数据，帮助VLM克服了灾难性遗忘，确保了模型知识的长期保持。此外，LLMs在指导合成数据生成中的作用日益凸显，它们能够为复杂场景定义语义约束和高层次指令，从而生成更具情境感知的训练数据。

然而，尽管取得了这些进展，“现实差距”和数据保真度问题依然是核心挑战，要求持续创新以确保合成数据在物理和行为上与真实世界无缝衔接。同时，合成数据带来的伦理考量，如误报风险、隐私泄露和偏见放大，以及VLA模型在物理世界中可能产生的有害行为，都强调了在技术发展的同时，必须建立健全的伦理框架和验证机制。未来的研究将重点关注如何进一步缩小Sim-to-Real差距、提高计算效率、开发更智能的合成数据生成方法，并确保VLA模型在复杂且不可预测的现实环境中安全、可靠地运行。这些努力将共同推动具身AI迈向更广泛、更负责任的应用前景。

飞书
**合成数据生成简介**

合成数据生成（SDG）是指创建人工数据以复制现实世界数据的特征、结构和统计属性的过程。这些数据通过算法、模型和模拟生成，当现实数据不足、采集成本高或难以获取时，这种方法尤为有价值。通过将合成数据与现实数据结合，可以显著提升数据集的规模和代表性，从而训练出更鲁棒的模型。

**合成数据生成的关键技术**

1. **模拟（仿真环境）**：通过模拟现实环境或行为生成合成数据。这种方法在数学或统计上复现真实场景，尤其适用于生成多样化数据集。
2. **生成式 AI：** 使用先进的 AI 模型从真实数据中学习模式，生成与原始数据高度相似的合成数据集。一个相关示例可参考技术博客 [《使用 OpenUSD 和合成数据开发托盘检测模型》](https://developer.nvidia.com/blog/developing-a-pallet-detection-model-using-openusd-and-synthetic-data/)。
- 利用仿真环境（如 NVIDIA Isaac Sim）与生成模型（如 DreamGen, RoboTwin）合成大规模操控数据；
- 讨论Sim-to-Real迁移难点与物理一致性建模挑战。
**建议**

- 可参考仿真类综述
- 可找一些解决sim2real gap的问题的论文（少量有代表性即可）
- 找一批用大量合成数据训练的模型（gr00t n1、grasp vla等）
- - **[Sim2Real Gap](https://bcnz00u39nfh.feishu.cn/wiki/N1xkwlhbSi3G7qkuRO0cE4XCnPd?from=from_copylink)** **可作为参考**
- **问题**：存在sim2real gap、高质量仿真数据（assets、物理特性等）难以建模，无法完全模拟真实世界
